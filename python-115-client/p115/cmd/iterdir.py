#!/usr/bin/env python3
# coding: utf-8

__author__ = "ChenyangGao <https://chenyanggao.github.io>"
__all__: list[str] = []
__doc__ = "115 æ–‡ä»¶å¤¹ä¿¡æ¯éå†å¯¼å‡º"

KEYS = (
    "id", "parent_id", "name", "path", "relpath", "size", "sha1", "pickcode", 
    "is_directory", "ctime", "mtime", "atime", "hidden", "violated", "play_long", 
    "thumb", "star", "score", "labels", "description", 
)

if __name__ == "__main__":
    from argparse import ArgumentParser, RawTextHelpFormatter
    from pathlib import Path
    from sys import path

    path[0] = str(Path(__file__).parents[2])
    parser = ArgumentParser(description=__doc__, formatter_class=RawTextHelpFormatter)
else:
    from argparse import RawTextHelpFormatter
    from .init import subparsers

    parser = subparsers.add_parser("iterdir", description=__doc__, formatter_class=RawTextHelpFormatter)


def main(args):
    if args.version:
        from p115 import __version__
        print(".".join(map(str, __version__)))
        raise SystemExit(0)

    from collections.abc import Callable, Sequence
    from functools import partial
    from os.path import expanduser, dirname, join as joinpath, realpath
    from sys import stdout

    from p115 import P115Client, P115Path

    cookies = args.cookies
    cookies_path = args.cookies_path
    if not cookies:
        if cookies_path:
            try:
                cookies = open(cookies_path).read()
            except FileNotFoundError:
                pass
        else:
            seen = set()
            for dir_ in (".", expanduser("~"), dirname(__file__)):
                dir_ = realpath(dir_)
                if dir_ in seen:
                    continue
                seen.add(dir_)
                try:
                    cookies = open(joinpath(dir_, "115-cookies.txt")).read()
                    if cookies:
                        cookies_path = joinpath(dir_, "115-cookies.txt")
                        break
                except FileNotFoundError:
                    pass

    client = P115Client(cookies, app=args.app)
    if cookies_path and cookies != client.cookies:
        open(cookies_path, "w").write(client.cookies)

    do_request: None | Callable
    match args.use_request:
        case "httpx":
            do_request = None
        case "requests":
            try:
                from requests import Session
                from requests_request import request as requests_request
            except ImportError:
                from sys import executable
                from subprocess import run
                run([executable, "-m", "pip", "install", "-U", "requests", "requests_request"], check=True)
                from requests import Session
                from requests_request import request as requests_request
            do_request = partial(requests_request, session=Session())
        case "urllib3":
            try:
                from urllib3_request import request as do_request
            except ImportError:
                from sys import executable
                from subprocess import run
                run([executable, "-m", "pip", "install", "-U", "urllib3", "urllib3_request"], check=True)
                from urllib3_request import request as do_request
        case "urlopen":
            try:
                from urlopen import request as urlopen_request
            except ImportError:
                from sys import executable
                from subprocess import run
                run([executable, "-m", "pip", "install", "-U", "python-urlopen"], check=True)
                from urlopen import request as urlopen_request
            do_request = partial(urlopen_request, cookies=client.cookiejar)

    fs = client.get_fs(request=do_request)

    if args.password and not fs.hidden_mode:
        fs.hidden_switch(True, password=args.password)

    keys: Sequence[str]
    if args.kind_keys:
        keys = ["id", "parent_id", "name", "path", "relpath", "size", "sha1", "pickcode", "is_directory"]
        if args.keys:
            for k in args.keys:
                if k not in keys:
                    keys.append(k)
    else:
        keys = args.keys or KEYS
    output_type = args.output_type

    path = args.path
    if path.isdecimal():
        fid = int(path)
        attr = fs.attr(fid)
    else:
        attr = fs.attr(path)
        fid = attr["id"]
    top_start = len(attr["path"]) + 1

    select = args.select
    if select:
        if select.startswith("lambda "):
            predicate = eval(select)
        else:
            predicate = eval("lambda path:" + select)
    else:
        predicate = None

    path_it = fs.iter(
        fid, 
        predicate=predicate, 
        min_depth=args.min_depth, 
        max_depth=args.max_depth, 
        topdown=True if args.depth_first else None, 
    )

    output_file = args.output_file
    if output_file:
        from collections import deque
        from time import perf_counter

        def format_time(t):
            m, s = divmod(t, 60)
            if m < 60:
                return f"{m:02.0f}:{s:09.06f}"
            h, m = divmod(m, 60)
            if h < 24:
                return f"{h:02.0f}:{m:02.0f}:{s:09.06f}"
            d, h = divmod(h, 60)
            return f"{d}d{h:02.0f}:{m:02.0f}:{s:09.06f}"

        def progress(it):
            write = stdout.buffer.raw.write # type: ignore
            dq: deque[tuple[int, float]] = deque(maxlen=10*60)
            push = dq.append
            total = 0
            ndirs = 0
            nfiles = 0
            start_t = last_t = perf_counter()
            write(f"\r\x1b[KğŸ—‚ï¸  {total} = ğŸ“‚ {ndirs} + ğŸ“ {nfiles}".encode())
            push((total, start_t))
            for p in it:
                total += 1
                if p.is_dir():
                    ndirs += 1
                else:
                    nfiles += 1
                cur_t = perf_counter()
                if cur_t - last_t > 0.1:
                    speed = (total - dq[0][0]) / (cur_t - dq[0][1])
                    write(f"\r\x1b[KğŸ—‚ï¸  {total} = ğŸ“‚ {ndirs} + ğŸ“ {nfiles} | ğŸ•™ {format_time(cur_t-start_t)} | ğŸš€ {speed:.3f} it/s".encode())
                    push((total, cur_t))
                    last_t = cur_t
                yield p
            cur_t = perf_counter()
            speed = total / (cur_t - start_t)
            write(f"\r\x1b[KğŸ—‚ï¸  {total} = ğŸ“‚ {ndirs} + ğŸ“ {nfiles} | ğŸ•™ {format_time(cur_t-start_t)} | ğŸš€ {speed:.3f} it/s".encode())
        file = open(output_file, "w")
        path_it = iter(progress(path_it))
    else:
        file = stdout # type: ignore

    from textwrap import dedent

    dump_code = dedent(args.dump).strip()
    if dump_code:
        if args.dump_exec:
            ns: dict = {}
            exec(dump_code, ns)
            dump = ns["dump"]
        else:
            code = compile(dump_code, "", "eval")
            dump = lambda path: eval(code, {"path": path})
        if output_file:
            write = file.buffer.write
        else:
            write = file.buffer.raw.write # type: ignore
        for path in path_it:
            result = dump(path)
            if not (result is None or isinstance(result, bytes)):
                result = bytes(str(result), "utf-8")
            if result:
                write(result)
                write(b"\n")
        return

    def get_key(path: P115Path, key: str):
        if key == "description":
            if path.get('described'):
                return path.desc
            else:
                return ""
        elif key == "relpath":
            return path["path"][top_start:]
        else:
            return path.get(key)

    records = ({k: get_key(p, k) for k in keys} for p in path_it)

    dumps: Callable[..., bytes]
    if output_type in ("log", "json"):
        try:
            from orjson import dumps
        except ImportError:
            odumps: Callable[..., str]
            try:
                from ujson import dumps as odumps
            except ImportError:
                from json import dumps as odumps
            dumps = lambda obj: bytes(odumps(obj, ensure_ascii=False), "utf-8")
        if output_file:
            write = file.buffer.write
        else:
            write = file.buffer.raw.write # type: ignore

    try:
        if output_type == "json":
            write(b"[")
            for i, record in enumerate(records):
                if i:
                    write(b", ")
                write(dumps(record))
            write(b"]")
        elif output_type == "log":
            for record in records:
                write(dumps(record))
                write(b"\n")
        else:
            from csv import DictWriter

            writer = DictWriter(file, fieldnames=keys)
            writer.writeheader()
            for record in records:
                writer.writerow(record)
    except KeyboardInterrupt:
        pass
    except BrokenPipeError:
        from sys import stderr
        stderr.close()
    finally:
        file.close()


from p115 import AVAILABLE_APPS

parser.add_argument("path", nargs="?", default="0", help="æ–‡ä»¶å¤¹è·¯å¾„æˆ– idï¼Œé»˜è®¤å€¼ 0ï¼Œå³æ ¹ç›®å½•")
parser.add_argument("-c", "--cookies", help="115 ç™»å½• cookiesï¼Œä¼˜å…ˆçº§é«˜äº -c/--cookies-path")
parser.add_argument("-cp", "--cookies-path", help="""\
å­˜å‚¨ 115 ç™»å½• cookies çš„æ–‡æœ¬æ–‡ä»¶çš„è·¯å¾„ï¼Œå¦‚æœç¼ºå¤±ï¼Œåˆ™ä» 115-cookies.txt æ–‡ä»¶ä¸­è·å–ï¼Œæ­¤æ–‡ä»¶å¯åœ¨å¦‚ä¸‹ç›®å½•ä¹‹ä¸€: 
    1. å½“å‰å·¥ä½œç›®å½•
    2. ç”¨æˆ·æ ¹ç›®å½•
    3. æ­¤è„šæœ¬æ‰€åœ¨ç›®å½•""")
parser.add_argument(
    "-a", "--app", default="qandroid", 
    choices=AVAILABLE_APPS, 
    help="å¿…è¦æ—¶ï¼Œé€‰æ‹©ä¸€ä¸ª app è¿›è¡Œæ‰«ç ç™»å½•ï¼Œé»˜è®¤å€¼ 'qandroid'ï¼Œæ³¨æ„ï¼šè¿™ä¼šæŠŠå·²ç»ç™»å½•çš„ç›¸åŒ app è¸¢ä¸‹çº¿")
parser.add_argument("-p", "--password", help="å¯†ç ï¼Œç”¨äºè¿›å…¥éšè—æ¨¡å¼ï¼Œç½—åˆ—éšè—æ–‡ä»¶")
parser.add_argument("-s", "--select", help="æä¾›ä¸€ä¸ªè¡¨è¾¾å¼ï¼ˆä¼šæ³¨å…¥ä¸€ä¸ªå˜é‡ pathï¼Œç±»å‹æ˜¯ p115.P115Pathï¼‰ï¼Œç”¨äºå¯¹è·¯å¾„è¿›è¡Œç­›é€‰")
parser.add_argument("-k", "--keys", nargs="*", choices=KEYS, help=f"é€‰æ‹©è¾“å‡ºçš„ keyï¼Œé»˜è®¤è¾“å‡ºæ‰€æœ‰å¯é€‰å€¼")
parser.add_argument("-kk", "--kind-keys", action="store_true", help="å¸®ä½ é€‰å¥½çš„ä¸€ç»„ keyï¼Œç›¸å½“äºï¼š-k id parent_id name path size sha1 pickcode is_directory")
parser.add_argument("-t", "--output-type", choices=("log", "json", "csv"), default="log", help="""\
è¾“å‡ºç±»å‹ï¼Œé»˜è®¤ä¸º log
    - log   æ¯è¡Œè¾“å‡ºä¸€æ¡æ•°æ®ï¼Œæ¯æ¡æ•°æ®è¾“å‡ºä¸ºä¸€ä¸ª json çš„ object
    - json  è¾“å‡ºä¸€ä¸ª json çš„ listï¼Œæ¯æ¡æ•°æ®è¾“å‡ºä¸ºä¸€ä¸ª json çš„ object
    - csv   è¾“å‡ºä¸€ä¸ª csvï¼Œç¬¬ 1 è¡Œä¸ºè¡¨å¤´ï¼Œä»¥åæ¯è¡Œè¾“å‡ºä¸€æ¡æ•°æ®""")
parser.add_argument("-d", "--dump", default="", help="""\
(ä¼˜å…ˆçº§é«˜äº -k/--keys å’Œ -t/--output-type) æä¾›ä¸€æ®µä»£ç ï¼Œæ¯æ¬¡è°ƒç”¨ï¼Œå†è¡Œè¾“å‡ºï¼Œå°¾éƒ¨ä¼šæ·»åŠ ä¸€ä¸ª b'\n'ã€‚
å¦‚æœç»“æœ result æ˜¯
    - Noneï¼Œè·³è¿‡
    - bytesï¼Œè¾“å‡º
    - å…¶å®ƒï¼Œå…ˆè°ƒç”¨ `bytes(str(result), 'utf-8')`ï¼Œå†è¾“å‡º""")
parser.add_argument("-de", "--dump-exec", action="store_true", help="å¯¹ dump ä»£ç è¿›è¡Œ exec è§£æï¼ˆå¿…é¡»ç”Ÿæˆä¸€ä¸ªå˜é‡ dumpï¼Œç”¨äºè°ƒç”¨ï¼‰ï¼Œå¦åˆ™ç”¨ eval è§£æï¼ˆä¼šæ³¨å…¥ä¸€ä¸ªå˜é‡ pathï¼Œç±»å‹æ˜¯ p115.P115Pathï¼‰")
parser.add_argument("-o", "--output-file", help="ä¿å­˜åˆ°æ–‡ä»¶ï¼Œæ­¤æ—¶å‘½ä»¤è¡Œä¼šè¾“å‡ºè¿›åº¦æ¡")
parser.add_argument("-m", "--min-depth", default=0, type=int, help="æœ€å°æ·±åº¦ï¼Œé»˜è®¤å€¼ 0ï¼Œå°äºæˆ–ç­‰äº 0 æ—¶ä¸é™")
parser.add_argument("-M", "--max-depth", default=-1, type=int, help="æœ€å¤§æ·±åº¦ï¼Œé»˜è®¤å€¼ -1ï¼Œå°äº 0 æ—¶ä¸é™")
parser.add_argument("-dfs", "--depth-first", action="store_true", help="ä½¿ç”¨æ·±åº¦ä¼˜å…ˆæœç´¢ï¼Œå¦åˆ™ä½¿ç”¨å¹¿åº¦ä¼˜å…ˆ")
parser.add_argument("-ur", "--use-request", choices=("httpx", "requests", "urllib3", "urlopen"), default="httpx", help="é€‰æ‹©ä¸€ä¸ªç½‘ç»œè¯·æ±‚æ¨¡å—ï¼Œé»˜è®¤å€¼ï¼šhttpx")
parser.add_argument("-v", "--version", action="store_true", help="è¾“å‡ºç‰ˆæœ¬å·")
parser.set_defaults(func=main)


if __name__ == "__main__":
    args = parser.parse_args()
    main(args)

