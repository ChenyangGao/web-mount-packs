#!/usr/bin/env python3
# coding: utf-8

__author__ = "ChenyangGao <https://chenyanggao.github.io>"
__all__ = ["main"]
__doc__ = "115 ç½‘ç›˜æ‰¹é‡ä¸Šä¼ "

from argparse import ArgumentParser, Namespace, RawTextHelpFormatter
from pathlib import Path

if __name__ == "__main__":
    from sys import path

    path[0] = str(Path(__file__).parents[2])
    parser = ArgumentParser(description=__doc__, formatter_class=RawTextHelpFormatter)
else:
    from .init import subparsers

    parser = subparsers.add_parser("upload", description=__doc__, formatter_class=RawTextHelpFormatter)

from collections.abc import Mapping
from dataclasses import dataclass, field
from typing import NamedTuple, TypedDict


@dataclass
class Task:
    src_attr: Mapping
    dst_pid: int
    dst_attr: None | str | Mapping = None
    times: int = 0
    reasons: list[BaseException] = field(default_factory=list)


class Tasks(TypedDict):
    success: dict[str, Task]
    failed: dict[str, Task]
    unfinished: dict[str, Task]


class Result(NamedTuple):
    stats: dict
    tasks: Tasks


def get_status_code(e: BaseException, /) -> int:
    status = getattr(e, "status", None) or getattr(e, "code", None) or getattr(e, "status_code", None)
    if status is None and hasattr(e, "response"):
        response = e.response
        status = (
            getattr(response, "status", None) or 
            getattr(response, "code", None) or 
            getattr(response, "status_code", None)
        )
    return status or 0


def parse_args(argv: None | list[str] = None, /) -> Namespace:
    args = parser.parse_args(argv)
    if args.version:
        from p115 import __version__
        print(".".join(map(str, __version__)))
        raise SystemExit(0)
    return args


def main(argv: None | list[str] | Namespace = None, /):
    if isinstance(argv, Namespace):
        args = argv
    else:
        args = parse_args(argv)

    import errno

    from collections.abc import Callable
    from contextlib import contextmanager
    from datetime import datetime
    from functools import partial
    from os import fspath, remove, removedirs, scandir, stat
    from os.path import dirname, normpath
    from textwrap import indent
    from threading import Lock
    from traceback import format_exc
    from typing import cast, ContextManager
    from urllib.error import URLError

    from concurrenttools import thread_batch
    from hashtools import file_digest
    from p115 import check_response, MultipartUploadAbort, MultipartResumeData
    from p115.component import P115Client
    from posixpatht import escape, joinpath as pjoinpath, normpath as pnormpath, split as psplit, path_is_dir_form
    from rich.progress import (
        Progress, DownloadColumn, FileSizeColumn, MofNCompleteColumn, SpinnerColumn, 
        TimeElapsedColumn, TransferSpeedColumn, 
    )
    from texttools import rotate_text

    if not (cookies := args.cookies):
        if cookies_path := args.cookies_path:
            cookies = Path(cookies_path)
        else:
            cookies = Path("115-cookies.txt")
    client = P115Client(cookies, check_for_relogin=True, ensure_cookies=True, app="qandroid")

    src_path = args.src_path
    dst_path = args.dst_path
    part_size = args.part_size
    use_request = args.use_request
    max_workers = args.max_workers
    max_retries = args.max_retries
    resume = args.resume
    remove_done = args.remove_done
    with_root = args.with_root

    if max_workers <= 0:
        max_workers = 1
    count_lock: None | ContextManager = None
    if max_workers > 1:
        count_lock = Lock()

    do_request: None | Callable = None
    match use_request:
        case "httpx":
            from httpx import RequestError
        case "requests":
            try:
                from requests import Session
                from requests.exceptions import RequestException as RequestError # type: ignore
                from requests_request import request as requests_request
            except ImportError:
                from sys import executable
                from subprocess import run
                run([executable, "-m", "pip", "install", "-U", "requests", "requests_request"], check=True)
                from requests import Session
                from requests.exceptions import RequestException as RequestError # type: ignore
                from requests_request import request as requests_request
            do_request = partial(requests_request, session=Session())
        case "urllib3":
            try:
                from urllib3.exceptions import RequestError # type: ignore
                from urllib3_request import request as do_request
            except ImportError:
                from sys import executable
                from subprocess import run
                run([executable, "-m", "pip", "install", "-U", "urllib3", "urllib3_request"], check=True)
                from urllib3.exceptions import RequestError # type: ignore
                from urllib3_request import request as do_request
        case "urlopen":
            from urllib.error import URLError as RequestError # type: ignore
            from urllib.request import build_opener, HTTPCookieProcessor
            try:
                from urlopen import request as urlopen_request
            except ImportError:
                from sys import executable
                from subprocess import run
                run([executable, "-m", "pip", "install", "-U", "python-urlopen"], check=True)
                from urlopen import request as urlopen_request
            do_request = partial(urlopen_request, opener=build_opener(HTTPCookieProcessor(client.cookiejar)))

    fs = client.get_fs(request=do_request)

    @contextmanager
    def ensure_cm(cm):
        if isinstance(cm, ContextManager):
            with cm as val:
                yield val
        else:
            yield cm

    stats: dict = {
        # å¼€å§‹æ—¶é—´
        "start_time": datetime.now(), 
        # æ€»è€—æ—¶
        "elapsed": "", 
        # æºè·¯å¾„
        "src_path": "",  
        # ç›®æ ‡è·¯å¾„
        "dst_path": "", 
        # ä»»åŠ¡æ€»æ•°
        "tasks": {"total": 0, "files": 0, "dirs": 0, "size": 0}, 
        # æˆåŠŸä»»åŠ¡æ•°
        "success": {"total": 0, "files": 0, "dirs": 0, "size": 0}, 
        # å¤±è´¥ä»»åŠ¡æ•°ï¼ˆå‘ç”Ÿé”™è¯¯ä½†å·²æŠ›å¼ƒï¼‰
        "failed": {"total": 0, "files": 0, "dirs": 0, "size": 0}, 
        # é‡è¯•ä»»åŠ¡æ•°ï¼ˆå‘ç”Ÿé”™è¯¯ä½†å¯é‡è¯•ï¼‰ï¼Œä¸€ä¸ªä»»åŠ¡å¯ä»¥é‡è¯•å¤šæ¬¡
        "retry": {"total": 0, "files": 0, "dirs": 0}, 
        # æœªå®Œæˆä»»åŠ¡æ•°ï¼šæœªè¿è¡Œã€é‡è¯•ä¸­æˆ–è¿è¡Œä¸­
        "unfinished": {"total": 0, "files": 0, "dirs": 0, "size": 0}, 
        # å„ç§é”™è¯¯æ•°é‡å’Œåˆ†ç±»æ±‡æ€»
        "errors": {"total": 0, "files": 0, "dirs": 0, "reasons": {}}, 
        # æ˜¯å¦æ‰§è¡Œå®Œæˆï¼šå¦‚æœæ˜¯ Falseï¼Œè¯´æ˜æ˜¯è¢«äººä¸ºç»ˆæ­¢
        "is_completed": False, 
    }
    # ä»»åŠ¡æ€»æ•°
    tasks: dict[str, int] = stats["tasks"]
    # æˆåŠŸä»»åŠ¡æ•°
    success: dict[str, int] = stats["success"]
    # å¤±è´¥ä»»åŠ¡æ•°ï¼ˆå‘ç”Ÿé”™è¯¯ä½†å·²æŠ›å¼ƒï¼‰
    failed: dict[str, int] = stats["failed"]
    # é‡è¯•ä»»åŠ¡æ•°ï¼ˆå‘ç”Ÿé”™è¯¯ä½†å¯é‡è¯•ï¼‰ï¼Œä¸€ä¸ªä»»åŠ¡å¯ä»¥é‡è¯•å¤šæ¬¡
    retry: dict[str, int] = stats["retry"]
    # æœªå®Œæˆä»»åŠ¡æ•°ï¼šæœªè¿è¡Œã€é‡è¯•ä¸­æˆ–è¿è¡Œä¸­
    unfinished: dict[str, int] = stats["unfinished"]
    # å„ç§é”™è¯¯æ•°é‡å’Œåˆ†ç±»æ±‡æ€»
    errors: dict = stats["errors"]
    # å„ç§é”™è¯¯çš„åˆ†ç±»æ±‡æ€»
    reasons: dict[str, int] = errors["reasons"]
    # å¼€å§‹æ—¶é—´
    start_time = stats["start_time"]

    def get_path_attr(path) -> dict:
        if isinstance(path, str):
            path = Path(path)
        attr = {
            "path": fspath(path), 
            "name": path.name, 
            "is_directory": path.is_dir(), 
        }
        attr.update(zip(("mode", "inode", "dev", "nlink", "uid", "gid", "size", "atime", "mtime", "ctime"), path.stat()))
        return attr

    def update_tasks(total=1, files=0, size=0):
        dirs = total - files
        with ensure_cm(count_lock):
            tasks["total"] += total
            unfinished["total"] += total
            if dirs:
                tasks["dirs"] += dirs
                unfinished["dirs"] += dirs
            if files:
                tasks["files"] += files
                tasks["size"] += size
                unfinished["files"] += files
                unfinished["size"] += size

    def update_success(total=1, files=0, size=0):
        dirs = total - files
        with ensure_cm(count_lock):
            success["total"] += total
            unfinished["total"] -= total
            if dirs:
                success["dirs"] += dirs
                unfinished["dirs"] -= dirs
            if files:
                success["files"] += files
                success["size"] += size
                unfinished["files"] -= files
                unfinished["size"] -= size

    def update_failed(total=1, files=0, size=0):
        dirs = total - files
        with ensure_cm(count_lock):
            failed["total"] += total
            unfinished["total"] -= total
            if dirs:
                failed["dirs"] += dirs
                unfinished["dirs"] -= dirs
            if files:
                failed["files"] += files
                failed["size"] += size
                unfinished["files"] -= files
                unfinished["size"] -= size

    def update_retry(total=1, files=0):
        dirs = total - files
        with ensure_cm(count_lock):
            retry["total"] += total
            if dirs:
                retry["dirs"] += dirs
            if files:
                retry["files"] += files

    def update_errors(e, is_directory=False):
        exctype = type(e).__module__ + "." + type(e).__qualname__
        with ensure_cm(count_lock):
            errors["total"] += 1
            if is_directory:
                errors["dirs"] += 1
            else:
                errors["files"] += 1
            try:
                reasons[exctype] += 1
            except KeyError:
                reasons[exctype] = 1

    def hash_report(attr):
        update_desc = rotate_text(attr["name"], 22, interval=0.1).__next__
        task = progress.add_task("[bold blink red on yellow]DIGESTING[/bold blink red on yellow] " + update_desc(), total=attr["size"])
        def hash_progress(step):
            progress.update(task, description="[bold blink red on yellow]DIGESTING[/bold blink red on yellow] " + update_desc(), advance=step)
            progress.update(statistics_bar, description=get_stat_str())
        try:
            return file_digest(
                open(attr["path"], "rb"), 
                "sha1", 
                callback=hash_progress, 
            )
        finally:
            progress.remove_task(task)

    def add_report(_, attr):
        update_desc = rotate_text(attr["name"], 32, interval=0.1).__next__
        task = progress.add_task(update_desc(), total=attr["size"])
        try:
            while not closed:
                step = yield
                progress.update(task, description=update_desc(), advance=step)
                progress.update(statistics_bar, description=get_stat_str(), advance=step, total=tasks["size"])
        finally:
            progress.remove_task(task)

    def work(task: Task, submit):
        src_attr, dst_pid, dst_attr = task.src_attr, task.dst_pid, task.dst_attr
        src_path = src_attr["path"]
        if dst_attr is None:
            name: None | str = None
        elif isinstance(dst_attr, str):
            name = dst_attr
        else:
            name = cast(str, dst_attr["name"])
        try:
            task.times += 1
            if src_attr["is_directory"]:
                subdattrs: None | dict = None
                if not name:
                    dst_id = dst_pid
                else:
                    try:
                        if isinstance(dst_attr, str):
                            resp = check_response(fs.fs_mkdir(name, dst_pid))
                            name = cast(str, resp["file_name"])
                            dst_id = int(resp["file_id"])
                            task.dst_attr = {"id": dst_id, "parent_id": dst_pid, "name": name, "is_directory": True}
                            subdattrs = {}
                            console_print(f"[bold green][GOOD][/bold green] ğŸ“‚ åˆ›å»ºç›®å½•: [blue underline]{src_path!r}[/blue underline] âœ [blue underline]{name!r}[/blue underline] in {dst_pid}")
                        else:
                            dst_id = cast(Mapping, dst_attr)["id"]
                    except FileExistsError:
                        dst_attr = task.dst_attr = fs.attr([name], pid=dst_pid, ensure_dir=True)
                        dst_id = dst_attr["id"]
                if subdattrs is None:
                    subdattrs = {
                        (attr["name"], attr["is_directory"]): attr 
                        for attr in fs.listdir_attr(dst_id)
                    }
                subattrs = [
                    a for a in map(get_path_attr, scandir(src_path))
                    if a["name"] not in (".DS_Store", "Thumbs.db") and not a["name"].startswith("._")
                ]
                update_tasks(
                    total=len(subattrs), 
                    files=sum(not a["is_directory"] for a in subattrs), 
                    size=sum(a["size"] for a in subattrs if not a["is_directory"]), 
                )
                progress.update(statistics_bar, description=get_stat_str(), total=tasks["size"])
                pending_to_remove: list[int] = []
                for subattr in subattrs:
                    subname = subattr["name"]
                    subpath = subattr["path"]
                    is_directory = subattr["is_directory"]
                    key = subname, is_directory
                    if key in subdattrs:
                        subdattr = subdattrs[key]
                        subdpath = subdattr["path"]
                        if is_directory:
                            console_print(f"[bold yellow][SKIP][/bold yellow] ğŸ“‚ ç›®å½•å·²å»º: [blue underline]{subpath!r}[/blue underline] âœ [blue underline]{subdpath!r}[/blue underline]")
                            subtask = Task(subattr, dst_id, subdattr)
                        elif resume and subattr["size"] == subdattr["size"] and subattr["mtime"] <= subdattr["ctime"]:
                            console_print(f"[bold yellow][SKIP][/bold yellow] ğŸ“ è·³è¿‡æ–‡ä»¶: [blue underline]{subpath!r}[/blue underline] âœ [blue underline]{subdpath!r}[/blue underline]")
                            update_success(1, 1, subattr["size"])
                            progress.update(statistics_bar, description=get_stat_str())
                            continue
                        else:
                            subtask = Task(subattr, dst_id, subname)
                            pending_to_remove.append(subdattr["id"])
                    else:
                        subtask = Task(subattr, dst_id, subname)
                    unfinished_tasks[subpath] = subtask
                    submit(subtask)
                if not subattrs and remove_done:
                    try:
                        removedirs(src_path)
                    except OSError:
                        pass
                if pending_to_remove:
                    for i in range(0, len(pending_to_remove), 1_000):
                        part_ids = pending_to_remove[i:i+1_000]
                        try:
                            resp = fs.fs_delete(part_ids)
                            console_print(f"""\
[bold green][DELETE][/bold green] ğŸ“ åˆ é™¤æ–‡ä»¶åˆ—è¡¨
    â”œ ids({len(part_ids)}) = {part_ids}
    â”œ response = {resp}""")
                        except BaseException as e:
                            console_print(f"""[bold yellow][SKIP][/bold yellow] ğŸ“ åˆ é™¤æ–‡ä»¶åˆ—è¡¨å¤±è´¥
    â”œ ids({len(part_ids)}) = {part_ids}
    â”œ reason = [red]{type(e).__module__}.{type(e).__qualname__}[/red]: {e}""")
                update_success(1)
            else:
                if not name:
                    name = src_attr["name"]
                kwargs: dict = {}
                if src_attr["size"] <= 1 << 30: # 1 GB
                    # NOTE: 1 GB ä»¥å†…ä½¿ç”¨ç½‘é¡µç‰ˆä¸Šä¼ æ¥å£ï¼Œè¿™ä¸ªæ¥å£çš„ä¼˜åŠ¿æ˜¯ä¸Šä¼ å®Œæˆåä¼šè‡ªåŠ¨äº§ç”Ÿ 115 ç”Ÿæ´»äº‹ä»¶
                    kwargs["upload_directly"] = None
                elif src_attr["size"] > 1 << 34: # 16 GB
                    # NOTE: ä»‹äº 1 GB å’Œ 16 GB æ—¶ç›´æ¥æµå¼ä¸Šä¼ ï¼Œè¶…è¿‡ 16 GB æ—¶ï¼Œä½¿ç”¨åˆ†å—ä¸Šä¼ 
                    kwargs["partsize"] = part_size
                # TODO: å¦‚æœ 115 GB < src_attr["size"] <= 500 GBï¼Œåˆ™è®¡ç®— ed2k åç¦»çº¿ä¸‹è½½
                filesize, filehash = hash_report(src_attr)
                console_print(f"[bold green][HASH][/bold green] ğŸ§  è®¡ç®—å“ˆå¸Œ: sha1([blue underline]{src_path!r}[/blue underline]) = {filehash.hexdigest()!r}")
                kwargs["filesize"] = filesize
                kwargs["filesha1"] = filehash.hexdigest()
                ticket: MultipartResumeData
                for i in range(5):
                    if i:
                        console_print(f"""\
[bold yellow][RETRY][/bold yellow] ğŸ“ é‡è¯•ä¸Šä¼ : [blue underline]{src_path!r}[/blue underline] âœ [blue underline]{name!r}[/blue underline] in {dst_pid}
    â”œ ticket = {ticket}""")
                    try:
                        resp = client.upload_file(
                            src_path, 
                            name, 
                            pid=dst_pid, 
                            make_reporthook=partial(add_report, attr=src_attr), 
                            **kwargs, 
                        )
                        break
                    except MultipartUploadAbort as e:
                        exc = e
                        ticket = kwargs["multipart_resume_data"] = e.ticket
                else:
                    raise exc
                check_response(resp)
                if resp.get("status") == 2 and resp.get("statuscode") == 0:
                    prompt = "ç§’ä¼ æ–‡ä»¶"
                else:
                    prompt = "ä¸Šä¼ æ–‡ä»¶"
                console_print(f"""\
[bold green][GOOD][/bold green] ğŸ“ {prompt}: [blue underline]{src_path!r}[/blue underline] âœ [blue underline]{name!r}[/blue underline] in {dst_pid}
    â”œ response = {resp}""")
                update_success(1, 1, src_attr["size"])
                if remove_done:
                    try:
                        remove(src_path)
                    except OSError:
                        pass
                    try:
                        removedirs(dirname(src_path))
                    except OSError:
                        pass
            progress.update(statistics_bar, description=get_stat_str())
            success_tasks[src_path] = unfinished_tasks.pop(src_path)
        except BaseException as e:
            task.reasons.append(e)
            update_errors(e, src_attr["is_directory"])
            if max_retries < 0:
                status_code = get_status_code(e)
                if status_code:
                    retryable = status_code >= 500
                else:
                    retryable = isinstance(e, (RequestError, URLError, TimeoutError))
            else:
                retryable = task.times <= max_retries
            if retryable:
                console_print(f"""\
[bold red][FAIL][/bold red] â™»ï¸ å‘ç”Ÿé”™è¯¯ï¼ˆå°†é‡è¯•ï¼‰: [blue underline]{src_path!r}[/blue underline] âœ [blue underline]{name!r}[/blue underline] in {dst_pid}
    â”œ [red]{type(e).__module__}.{type(e).__qualname__}[/red]: {e}""")
                update_retry(1, not src_attr["is_directory"])
                submit(task)
            else:
                console_print(f"""\
[bold red][FAIL][/bold red] ğŸ’€ å‘ç”Ÿé”™è¯¯ï¼ˆå°†æŠ›å¼ƒï¼‰: [blue underline]{src_path!r}[/blue underline] âœ [blue underline]{name!r}[/blue underline] in {dst_pid}
{indent(format_exc().strip(), "    â”œ ")}""")
                progress.update(statistics_bar, description=get_stat_str())
                update_failed(1, not src_attr["is_directory"], src_attr.get("size"))
                failed_tasks[src_path] = unfinished_tasks.pop(src_path)
                if len(task.reasons) == 1:
                    raise
                else:
                    raise BaseExceptionGroup("max retries exceed", task.reasons)
    src_attr = get_path_attr(normpath(src_path))
    dst_attr: None | dict = None
    name: str = src_attr["name"]
    is_directory = src_attr["is_directory"]
    with Progress(
        SpinnerColumn(), 
        *Progress.get_default_columns(), 
        TimeElapsedColumn(), 
        MofNCompleteColumn(), 
        DownloadColumn(), 
        FileSizeColumn(), 
        TransferSpeedColumn(), 
    ) as progress:
        console_print = lambda msg: progress.console.print(f"[bold][[cyan]{datetime.now()}[/cyan]][/bold]", msg)
        if isinstance(dst_path, str):
            if dst_path == "0" or pnormpath(dst_path) in ("", "/"):
                dst_pid = 0
                dst_path = "/" + name
            elif not dst_path.startswith("0") and dst_path.isascii() and dst_path.isdecimal():
                dst_pid = int(dst_path)
            elif is_directory:
                dst_attr = fs.makedirs(dst_path, pid=0, exist_ok=True)
                dst_pid = dst_attr["id"]
            elif with_root or path_is_dir_form(dst_path):
                dst_attr = fs.makedirs(dst_path, pid=0, exist_ok=True)
                dst_pid = dst_attr["id"]
                dst_path = dst_attr["path"] + "/" + name
            else:
                dst_path = pnormpath("/" + dst_path)
                dst_dir, dst_name = psplit(dst_path)
                try:
                    dst_attr = fs.attr(dst_path)
                except FileNotFoundError:
                    dst_attr = fs.makedirs(dst_dir, pid=0, exist_ok=True)
                    dst_pid = dst_attr["id"]
                    name = dst_name
                else:
                    if dst_attr["is_directory"]:
                        dst_pid = dst_attr["id"]
                        dst_path += "/" + name
                    else:
                        dst_pid = dst_attr["parent_id"]
                        name = dst_name
        else:
            dst_pid = dst_path
        if is_directory:
            if with_root and name:
                dst_attr = fs.makedirs(name, pid=dst_pid, exist_ok=True)
                dst_pid = dst_attr["id"]
            elif not dst_attr:
                dst_attr = fs.attr(dst_pid)
                if not dst_attr["is_directory"]:
                    raise NotADirectoryError(errno.ENOTDIR, dst_path)
            dst_path = dst_attr["path"]
        elif dst_pid and not dst_attr:
            dst_attr = fs.attr(dst_pid)
            if dst_attr["is_directory"]:
                dst_path = dst_attr["path"] + "/" + name
            else:
                dst_pid = dst_attr["parent_id"]
                dst_path = dst_attr["path"]
        task = Task(src_attr, dst_pid, None if is_directory else name)
        unfinished_tasks: dict[str, Task] = {src_attr["path"]: task}
        success_tasks: dict[str, Task] = {}
        failed_tasks: dict[str, Task] = {}
        all_tasks: Tasks = {
            "success": success_tasks, 
            "failed": failed_tasks, 
            "unfinished": unfinished_tasks, 
        }
        stats["src_path"] = src_attr["path"]
        stats["dst_path"] = dst_path
        update_tasks(1, not src_attr["is_directory"], src_attr.get("size"))
        get_stat_str = lambda: f"ğŸ“Š [cyan bold]statistics[/cyan bold] ğŸ§® {tasks['total']} = ğŸ’¯ {success['total']} + â›” {failed['total']} + â³ {unfinished['total']}"
        statistics_bar = progress.add_task(get_stat_str(), total=tasks["size"])
        closed = False
        try:
            thread_batch(work, unfinished_tasks.values(), max_workers=max_workers)
            stats["is_completed"] = True
        finally:
            closed = True
            progress.remove_task(statistics_bar)
            stats["elapsed"] = str(datetime.now() - start_time)
            console_print(f"ğŸ“Š [cyan bold]statistics:[/cyan bold] {stats}")
    return Result(stats, all_tasks)


parser.epilog = """\
-------------------------

ğŸ« ä¸Šä¼ æ–¹å¼è¯´æ˜ï¼š
- å½“æ–‡ä»¶ <= 1 GB æ—¶ï¼Œä½¿ç”¨ç½‘é¡µç‰ˆæ¥å£ä¸Šä¼ 
- å½“æ–‡ä»¶ > 1 GB ä¸” <= 16 GB æ—¶ï¼Œä½¿ç”¨æ™®é€šä¸Šä¼ 
- å½“æ–‡ä»¶ > 16 GB æ—¶ï¼Œä½¿ç”¨åˆ†å—ä¸Šä¼ 

ğŸ›£ï¸ è·¯å¾„è§£æè¯´æ˜ï¼š
å¦‚æœæŒ‡å®šçš„ç½‘ç›˜è·¯å¾„ä»¥æ–œæ  "/" ç»“å°¾ï¼Œåˆ™è§†ä¸ºç›®å½•

ç›®å½•çš„åˆå¹¶ä¸Šä¼ ï¼Œæ˜¯æŒ‡æŠŠæœ¬åœ°ç›®å½•ä¸åŒ…æ‹¬è‡ªèº«ä¸Šä¼ åˆ°ç½‘ç›˜ç›®å½•ä¸­ï¼Œå±äºè‡ªå·±çš„ä¸€çº§ç›®å½•ï¼Œå°±ä¼šæ˜¯å±äºç½‘ç›˜ç›®å½•çš„ä¸€çº§ç›®å½•ã€‚è€Œæ™®é€šçš„ä¸Šä¼ ï¼Œæ˜¯æŒ‡åœ¨ç½‘ç›˜ç›®å½•ä¸‹ï¼Œåˆ›å»ºä¸€ä¸ªå’Œæœ¬åœ°ç›®å½•åŒåçš„ç›®å½•ï¼Œç„¶åæŠŠæœ¬åœ°ç›®å½•åˆå¹¶ä¸Šä¼ åˆ°è¿™ä¸ªç›®å½•ä¸­

å¦‚æœæœ¬åœ°è·¯å¾„æ˜¯ä¸€ä¸ªæ–‡ä»¶
    1. å¦‚æœ with_root ä¸º Falseï¼ˆé»˜è®¤ï¼‰
        - å¦‚æœç½‘ç›˜è·¯å¾„ä¸å­˜åœ¨ï¼Œåˆ™ä¸Šä¼ æ–‡ä»¶åˆ°æ­¤è·¯å¾„
        - å¦‚æœç½‘ç›˜è·¯å¾„æˆ– id æ˜¯ä¸€ä¸ªæ–‡ä»¶ï¼Œåˆ™ä¸Šä¼ åˆ°æ­¤æ–‡ä»¶ç›¸åŒè·¯å¾„ä¸‹
        - å¦‚æœç½‘ç›˜è·¯å¾„æˆ– id æ˜¯ä¸€ä¸ªç›®å½•ï¼Œåˆ™ä¸Šä¼ åˆ°æ­¤æ–‡ä»¶åˆ°æ­¤ç›®å½•ä¸‹
    2. å¦‚æœ with_root ä¸º Trueï¼Œæˆ–è€…ç½‘ç›˜è·¯å¾„ä»¥æ–œæ  "/" ç»“å°¾
        - å¦‚æœç½‘ç›˜è·¯å¾„ä¸å­˜åœ¨ï¼Œåˆ™ä¸Šä¼ æ–‡ä»¶åˆ°æ­¤ç›®å½•ä¸‹
        - å¦‚æœç½‘ç›˜è·¯å¾„æˆ– id æ˜¯ä¸€ä¸ªæ–‡ä»¶ï¼Œåˆ™ä¸Šä¼ åˆ°æ­¤æ–‡ä»¶ç›¸åŒè·¯å¾„ä¸‹
        - å¦‚æœç½‘ç›˜è·¯å¾„æˆ– id æ˜¯ä¸€ä¸ªç›®å½•ï¼Œåˆ™ä¸Šä¼ åˆ°æ­¤æ–‡ä»¶åˆ°æ­¤ç›®å½•ä¸‹
å¦‚æœæœ¬åœ°è·¯å¾„æ˜¯ä¸€ä¸ªç›®å½•
    1. å¦‚æœ with_root ä¸º Falseï¼ˆé»˜è®¤ï¼‰
        - å¦‚æœç½‘ç›˜è·¯å¾„ä¸å­˜åœ¨ï¼Œåˆ™æŠŠæœ¬åœ°ç›®å½•åˆå¹¶ä¸Šä¼ åˆ°æ­¤ç›®å½•ä¸‹
        - å¦‚æœç½‘ç›˜è·¯å¾„æˆ– id æ˜¯ä¸€ä¸ªæ–‡ä»¶ï¼Œåˆ™æŠ¥é”™ NotADirectoryError
        - å¦‚æœç½‘ç›˜è·¯å¾„æˆ– id æ˜¯ä¸€ä¸ªç›®å½•ï¼Œåˆ™æŠŠæœ¬åœ°ç›®å½•åˆå¹¶ä¸Šä¼ åˆ°æ­¤ç›®å½•ä¸‹
    2. å¦‚æœ with_root ä¸º True
        - å¦‚æœç½‘ç›˜è·¯å¾„ä¸å­˜åœ¨ï¼Œåˆ™æŠŠæœ¬åœ°ç›®å½•ä¸Šä¼ åˆ°æ­¤ç›®å½•ä¸‹
        - å¦‚æœç½‘ç›˜è·¯å¾„æˆ– id æ˜¯ä¸€ä¸ªæ–‡ä»¶ï¼Œåˆ™æŠ¥é”™ NotADirectoryError
        - å¦‚æœç½‘ç›˜è·¯å¾„æˆ– id æ˜¯ä¸€ä¸ªç›®å½•ï¼Œåˆ™æŠŠæœ¬åœ°ç›®å½•ä¸Šä¼ åˆ°æ­¤ç›®å½•ä¸‹
"""
parser.add_argument("-c", "--cookies", help="115 ç™»å½• cookiesï¼Œä¼˜å…ˆçº§é«˜äº -cp/--cookies-path")
parser.add_argument("-cp", "--cookies-path", help="cookies æ–‡ä»¶ä¿å­˜è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰å·¥ä½œç›®å½•ä¸‹çš„ 115-cookies.txt")
parser.add_argument("-p", "--src-path", default=".", help="æœ¬åœ°çš„è·¯å¾„ï¼Œé»˜è®¤æ˜¯å½“å‰å·¥ä½œç›®å½•")
parser.add_argument("-t", "--dst-path", default="/", help="""115 ç½‘ç›˜ä¸­çš„æ–‡ä»¶æˆ–ç›®å½•çš„ id æˆ–è·¯å¾„ï¼Œé»˜è®¤å€¼ï¼š"/"
å¦‚æœæƒ³è¦æŠŠæœ¬åœ°æ–‡ä»¶ä¸Šä¼ åˆ°ç½‘ç›˜ç›®å½•ä¸­ï¼Œä¸”æŒ‡å®šäº†è·¯å¾„è€Œä¸æ˜¯ idï¼Œåˆ™æœ€å¥½åœ¨è·¯å¾„å°¾éƒ¨åŠ ä¸€ä¸ªæ–œæ  "/" """)
parser.add_argument("-ps", "--part-size", default=1 << 30, type=int, help="åˆ†å—ä¸Šä¼ æ—¶çš„åˆ†å—å¤§å°ï¼Œå•ä½æ˜¯ Byteï¼Œé»˜è®¤ä¸º 1073741824ï¼Œå³ 1GB")

parser.add_argument("-m", "--max-workers", default=1, type=int, help="å¹¶å‘çº¿ç¨‹æ•°ï¼Œé»˜è®¤å€¼ 1")
parser.add_argument("-mr", "--max-retries", default=-1, type=int, 
                    help="""æœ€å¤§é‡è¯•æ¬¡æ•°ã€‚
    - å¦‚æœå°äº 0ï¼ˆé»˜è®¤ï¼‰ï¼Œåˆ™ä¼šå¯¹ä¸€äº›è¶…æ—¶ã€ç½‘ç»œè¯·æ±‚é”™è¯¯è¿›è¡Œæ— é™é‡è¯•ï¼Œå…¶å®ƒé”™è¯¯è¿›è¡ŒæŠ›å‡º
    - å¦‚æœç­‰äº 0ï¼Œåˆ™å‘ç”Ÿé”™è¯¯å°±æŠ›å‡º
    - å¦‚æœå¤§äº 0ï¼ˆå®é™…æ‰§è¡Œ 1+n æ¬¡ï¼Œç¬¬ä¸€æ¬¡ä¸å«é‡è¯•ï¼‰ï¼Œåˆ™å¯¹æ‰€æœ‰é”™è¯¯ç­‰ç±»é½è§‚ï¼Œåªè¦æ¬¡æ•°åˆ°è¾¾æ­¤æ•°å€¼å°±æŠ›å‡º""")
parser.add_argument("-ur", "--use-request", choices=("httpx", "requests", "urllib3", "urlopen"), default="httpx", help="é€‰æ‹©ä¸€ä¸ªç½‘ç»œè¯·æ±‚æ¨¡å—ï¼Œé»˜è®¤å€¼ï¼šhttpx")
parser.add_argument("-wr", "--with-root", action="store_true", help="ä¸Šä¼ æ—¶ï¼ŒæŠŠ -t/--dst-path è§†ä¸ºè¦ä¸Šä¼ åˆ°çš„çˆ¶ç›®å½•ï¼Œè€Œä¸æ˜¯é»˜è®¤ä¸ºæ ¹ç›®å½•")
parser.add_argument("-r", "--resume", action="store_true", help="æ–­ç‚¹ç»­ä¼ ")
parser.add_argument("-rm", "--remove-done", action="store_true", help="ä¸Šä¼ æˆåŠŸåï¼Œåˆ é™¤æœ¬åœ°æ–‡ä»¶")
parser.add_argument("-v", "--version", action="store_true", help="è¾“å‡ºç‰ˆæœ¬å·")
parser.set_defaults(func=main)


if __name__ == "__main__":
    main()

# TODO: statistics è¡Œè¦æœ‰æ›´è¯¦ç»†çš„ä¿¡æ¯ï¼Œå¦‚æœä¸€è¡Œä¸å¤Ÿï¼Œå°±å†åŠ ä¸€è¡Œ
# TODO: ä»¥åè¦æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œå¯ç”¨ åˆ†å—ä¸Šä¼  å’Œ æœ¬åœ°ä¿å­˜è¿›åº¦
# TODO: æ”¯æŒåœ¨ä¸Šä¼ çš„æ—¶å€™ï¼Œæ”¹å˜æ–‡ä»¶çš„åå­—ï¼Œç‰¹åˆ«æ˜¯æ”¹å˜äº†æ‰©å±•å
# TODO: å¦‚æœæ–‡ä»¶å¤§äºç‰¹å®šå¤§å°ï¼Œå°±ä¸èƒ½ç§’ä¼ ï¼Œéœ€è¦ç›´æ¥æŠ¥é”™ï¼ˆè€Œä¸éœ€è¦è¿›è¡Œå°è¯•ï¼‰
# TODO: æ”¯æŒæŠŠä¸€ä¸ªç›®å½•ä¸Šä¼ åˆ°å¦ä¸€ä¸ªç›®å½•ï¼ˆå¦‚æœæ‰©å±•åæ²¡æ”¹ï¼Œå°±ç›´æ¥å¤åˆ¶ï¼Œç„¶åæ”¹åï¼Œå¦åˆ™å°±ç§’ä¼ ï¼‰
# TODO: æ”¯æŒç›´æ¥ä»ä¸€ä¸ª115ç½‘ç›˜ç›´æ¥ä¸Šä¼ åˆ°å¦ä¸€ä¸ª115ç½‘ç›˜
