#!/usr/bin/env python3
# coding: utf-8

__author__ = "ChenyangGao <https://chenyanggao.github.io>"
__all__ = ["main"]
__doc__ = "115 ç½‘ç›˜æ‰¹é‡ä¸Šä¼ "

from argparse import ArgumentParser, Namespace, RawTextHelpFormatter
from pathlib import Path

if __name__ == "__main__":
    from sys import path

    path[0] = str(Path(__file__).parents[2])
    parser = ArgumentParser(description=__doc__, formatter_class=RawTextHelpFormatter)
else:
    from .init import subparsers

    parser = subparsers.add_parser("upload", description=__doc__, formatter_class=RawTextHelpFormatter)

from collections.abc import Mapping
from dataclasses import dataclass, field
from typing import NamedTuple, TypedDict


@dataclass
class Task:
    src_attr: Mapping
    dst_pid: int
    dst_attr: str | Mapping
    times: int = 0
    reasons: list[BaseException] = field(default_factory=list)


class Tasks(TypedDict):
    success: dict[str, Task]
    failed: dict[str, Task]
    unfinished: dict[str, Task]


class Result(NamedTuple):
    stats: dict
    tasks: Tasks


def get_status_code(e: BaseException, /) -> int:
    status = getattr(e, "status", None) or getattr(e, "code", None) or getattr(e, "status_code", None)
    if status is None and hasattr(e, "response"):
        response = e.response
        status = (
            getattr(response, "status", None) or 
            getattr(response, "code", None) or 
            getattr(response, "status_code", None)
        )
    return status or 0


def parse_args(argv: None | list[str] = None, /) -> Namespace:
    args = parser.parse_args(argv)
    if args.version:
        from p115 import __version__
        print(".".join(map(str, __version__)))
        raise SystemExit(0)
    return args


def main(argv: None | list[str] | Namespace = None, /):
    if isinstance(argv, Namespace):
        args = argv
    else:
        args = parse_args(argv)

    import errno

    from collections.abc import Callable
    from contextlib import contextmanager
    from datetime import datetime
    from functools import partial
    from os import environ, fspath, remove, removedirs, scandir, stat
    from os.path import dirname, normpath
    from textwrap import indent
    from threading import Lock
    from traceback import format_exc
    from typing import cast, ContextManager
    from urllib.error import URLError

    from concurrenttools import thread_batch
    from hashtools import file_digest
    from p115 import check_response, MultipartUploadAbort, MultipartResumeData
    from p115.component import P115Client
    from posixpatht import escape, split, normpath as pnormpath
    from rich.progress import (
        Progress, DownloadColumn, FileSizeColumn, MofNCompleteColumn, SpinnerColumn, 
        TimeElapsedColumn, TransferSpeedColumn, 
    )
    from texttools import rotate_text

    if not (cookies := args.cookies):
        if cookies_path := args.cookies_path:
            cookies = Path(cookies_path)
        else:
            cookies = Path("115-cookies.txt")
    client = P115Client(cookies, check_for_relogin=True, ensure_cookies=True, app="qandroid")
    environ["WEBAPI_BASE_URL"] = ""

    src_path = args.src_path
    dst_path = args.dst_path
    use_request = args.use_request
    max_workers = args.max_workers
    max_retries = args.max_retries
    resume = args.resume
    remove_done = args.remove_done
    no_root = args.no_root

    if max_workers <= 0:
        max_workers = 1
    count_lock: None | ContextManager = None
    if max_workers > 1:
        count_lock = Lock()

    do_request: None | Callable = None
    match use_request:
        case "httpx":
            from httpx import RequestError
        case "requests":
            try:
                from requests import Session
                from requests.exceptions import RequestException as RequestError # type: ignore
                from requests_request import request as requests_request
            except ImportError:
                from sys import executable
                from subprocess import run
                run([executable, "-m", "pip", "install", "-U", "requests", "requests_request"], check=True)
                from requests import Session
                from requests.exceptions import RequestException as RequestError # type: ignore
                from requests_request import request as requests_request
            do_request = partial(requests_request, session=Session())
        case "urllib3":
            try:
                from urllib3.exceptions import RequestError # type: ignore
                from urllib3_request import request as do_request
            except ImportError:
                from sys import executable
                from subprocess import run
                run([executable, "-m", "pip", "install", "-U", "urllib3", "urllib3_request"], check=True)
                from urllib3.exceptions import RequestError # type: ignore
                from urllib3_request import request as do_request
        case "urlopen":
            from urllib.error import URLError as RequestError # type: ignore
            from urllib.request import build_opener, HTTPCookieProcessor
            try:
                from urlopen import request as urlopen_request
            except ImportError:
                from sys import executable
                from subprocess import run
                run([executable, "-m", "pip", "install", "-U", "python-urlopen"], check=True)
                from urlopen import request as urlopen_request
            do_request = partial(urlopen_request, opener=build_opener(HTTPCookieProcessor(client.cookiejar)))

    fs = client.get_fs(request=do_request)

    @contextmanager
    def ensure_cm(cm):
        if isinstance(cm, ContextManager):
            with cm as val:
                yield val
        else:
            yield cm

    stats: dict = {
        # å¼€å§‹æ—¶é—´
        "start_time": datetime.now(), 
        # æ€»è€—æ—¶
        "elapsed": "", 
        # æºè·¯å¾„
        "src_path": "",  
        # ç›®æ ‡è·¯å¾„
        "dst_path": "", 
        # ä»»åŠ¡æ€»æ•°
        "tasks": {"total": 0, "files": 0, "dirs": 0, "size": 0}, 
        # æˆåŠŸä»»åŠ¡æ•°
        "success": {"total": 0, "files": 0, "dirs": 0, "size": 0}, 
        # å¤±è´¥ä»»åŠ¡æ•°ï¼ˆå‘ç”Ÿé”™è¯¯ä½†å·²æŠ›å¼ƒï¼‰
        "failed": {"total": 0, "files": 0, "dirs": 0, "size": 0}, 
        # é‡è¯•ä»»åŠ¡æ•°ï¼ˆå‘ç”Ÿé”™è¯¯ä½†å¯é‡è¯•ï¼‰ï¼Œä¸€ä¸ªä»»åŠ¡å¯ä»¥é‡è¯•å¤šæ¬¡
        "retry": {"total": 0, "files": 0, "dirs": 0}, 
        # æœªå®Œæˆä»»åŠ¡æ•°ï¼šæœªè¿è¡Œã€é‡è¯•ä¸­æˆ–è¿è¡Œä¸­
        "unfinished": {"total": 0, "files": 0, "dirs": 0, "size": 0}, 
        # å„ç§é”™è¯¯æ•°é‡å’Œåˆ†ç±»æ±‡æ€»
        "errors": {"total": 0, "files": 0, "dirs": 0, "reasons": {}}, 
        # æ˜¯å¦æ‰§è¡Œå®Œæˆï¼šå¦‚æžœæ˜¯ Falseï¼Œè¯´æ˜Žæ˜¯è¢«äººä¸ºç»ˆæ­¢
        "is_completed": False, 
    }
    # ä»»åŠ¡æ€»æ•°
    tasks: dict[str, int] = stats["tasks"]
    # æˆåŠŸä»»åŠ¡æ•°
    success: dict[str, int] = stats["success"]
    # å¤±è´¥ä»»åŠ¡æ•°ï¼ˆå‘ç”Ÿé”™è¯¯ä½†å·²æŠ›å¼ƒï¼‰
    failed: dict[str, int] = stats["failed"]
    # é‡è¯•ä»»åŠ¡æ•°ï¼ˆå‘ç”Ÿé”™è¯¯ä½†å¯é‡è¯•ï¼‰ï¼Œä¸€ä¸ªä»»åŠ¡å¯ä»¥é‡è¯•å¤šæ¬¡
    retry: dict[str, int] = stats["retry"]
    # æœªå®Œæˆä»»åŠ¡æ•°ï¼šæœªè¿è¡Œã€é‡è¯•ä¸­æˆ–è¿è¡Œä¸­
    unfinished: dict[str, int] = stats["unfinished"]
    # å„ç§é”™è¯¯æ•°é‡å’Œåˆ†ç±»æ±‡æ€»
    errors: dict = stats["errors"]
    # å„ç§é”™è¯¯çš„åˆ†ç±»æ±‡æ€»
    reasons: dict[str, int] = errors["reasons"]
    # å¼€å§‹æ—¶é—´
    start_time = stats["start_time"]

    def get_path_attr(path) -> dict:
        if isinstance(path, str):
            path = Path(path)
        attr = {
            "path": fspath(path), 
            "name": path.name, 
            "is_directory": path.is_dir(), 
        }
        attr.update(zip(("mode", "inode", "dev", "nlink", "uid", "gid", "size", "atime", "mtime", "ctime"), path.stat()))
        return attr

    def update_tasks(total=1, files=0, size=0):
        dirs = total - files
        with ensure_cm(count_lock):
            tasks["total"] += total
            unfinished["total"] += total
            if dirs:
                tasks["dirs"] += dirs
                unfinished["dirs"] += dirs
            if files:
                tasks["files"] += files
                tasks["size"] += size
                unfinished["files"] += files
                unfinished["size"] += size

    def update_success(total=1, files=0, size=0):
        dirs = total - files
        with ensure_cm(count_lock):
            success["total"] += total
            unfinished["total"] -= total
            if dirs:
                success["dirs"] += dirs
                unfinished["dirs"] -= dirs
            if files:
                success["files"] += files
                success["size"] += size
                unfinished["files"] -= files
                unfinished["size"] -= size

    def update_failed(total=1, files=0, size=0):
        dirs = total - files
        with ensure_cm(count_lock):
            failed["total"] += total
            unfinished["total"] -= total
            if dirs:
                failed["dirs"] += dirs
                unfinished["dirs"] -= dirs
            if files:
                failed["files"] += files
                failed["size"] += size
                unfinished["files"] -= files
                unfinished["size"] -= size

    def update_retry(total=1, files=0):
        dirs = total - files
        with ensure_cm(count_lock):
            retry["total"] += total
            if dirs:
                retry["dirs"] += dirs
            if files:
                retry["files"] += files

    def update_errors(e, is_directory=False):
        exctype = type(e).__module__ + "." + type(e).__qualname__
        with ensure_cm(count_lock):
            errors["total"] += 1
            if is_directory:
                errors["dirs"] += 1
            else:
                errors["files"] += 1
            try:
                reasons[exctype] += 1
            except KeyError:
                reasons[exctype] = 1

    def hash_report(attr):
        update_desc = rotate_text(attr["name"], 22, interval=0.1).__next__
        task = progress.add_task("[bold blink red on yellow]DIGESTING[/bold blink red on yellow] " + update_desc(), total=attr["size"])
        def hash_progress(step):
            progress.update(task, description="[bold blink red on yellow]DIGESTING[/bold blink red on yellow] " + update_desc(), advance=step)
            progress.update(statistics_bar, description=get_stat_str())
        try:
            return file_digest(
                open(attr["path"], "rb"), 
                "sha1", 
                callback=hash_progress, 
            )
        finally:
            progress.remove_task(task)

    def add_report(_, attr):
        update_desc = rotate_text(attr["name"], 32, interval=0.1).__next__
        task = progress.add_task(update_desc(), total=attr["size"])
        try:
            while not closed:
                step = yield
                progress.update(task, description=update_desc(), advance=step)
                progress.update(statistics_bar, description=get_stat_str(), advance=step, total=tasks["size"])
        finally:
            progress.remove_task(task)

    def work(task: Task, submit):
        src_attr, dst_pid, dst_attr = task.src_attr, task.dst_pid, task.dst_attr
        src_path = src_attr["path"]
        name = dst_attr if isinstance(dst_attr, str) else dst_attr["name"]
        try:
            task.times += 1
            if src_attr["is_directory"]:
                subdattrs: None | dict = None
                try:
                    if isinstance(dst_attr, str):
                        resp = check_response(fs.fs_mkdir(name, dst_pid))
                        name = resp["file_name"]
                        dst_id = int(resp["file_id"])
                        task.dst_attr = {"id": dst_id, "parent_id": dst_pid, "name": name, "is_directory": True}
                        subdattrs = {}
                        console_print(f"[bold green][GOOD][/bold green] ðŸ“‚ åˆ›å»ºç›®å½•: [blue underline]{src_path!r}[/blue underline] âžœ [blue underline]{name!r}[/blue underline] in {dst_pid}")
                except FileExistsError:
                    dst_attr = task.dst_attr = fs.attr([name], pid=dst_pid, ensure_dir=True)
                if subdattrs is None:
                    dst_id = cast(Mapping, dst_attr)["id"]
                    subdattrs = {
                        (attr["name"], attr["is_directory"]): attr 
                        for attr in fs.listdir_attr(dst_id)
                    }
                subattrs = [
                    a for a in map(get_path_attr, scandir(src_path))
                    if a["name"] not in (".DS_Store", "Thumbs.db") and not a["name"].startswith("._")
                ]
                update_tasks(
                    total=len(subattrs), 
                    files=sum(not a["is_directory"] for a in subattrs), 
                    size=sum(a["size"] for a in subattrs if not a["is_directory"]), 
                )
                progress.update(statistics_bar, description=get_stat_str(), total=tasks["size"])
                pending_to_remove: list[int] = []
                for subattr in subattrs:
                    subname = subattr["name"]
                    subpath = subattr["path"]
                    is_directory = subattr["is_directory"]
                    key = subname, is_directory
                    if key in subdattrs:
                        subdattr = subdattrs[key]
                        subdpath = subdattr["path"]
                        if is_directory:
                            console_print(f"[bold yellow][SKIP][/bold yellow] ðŸ“‚ ç›®å½•å·²å»º: [blue underline]{subpath!r}[/blue underline] âžœ [blue underline]{subdpath!r}[/blue underline]")
                            subtask = Task(subattr, dst_id, subdattr)
                        elif resume and subattr["size"] == subdattr["size"] and subattr["mtime"] <= subdattr["ctime"]:
                            console_print(f"[bold yellow][SKIP][/bold yellow] ðŸ“ è·³è¿‡æ–‡ä»¶: [blue underline]{subpath!r}[/blue underline] âžœ [blue underline]{subdpath!r}[/blue underline]")
                            update_success(1, 1, subattr["size"])
                            progress.update(statistics_bar, description=get_stat_str())
                            continue
                        else:
                            subtask = Task(subattr, dst_id, subname)
                            pending_to_remove.append(subdattr["id"])
                    else:
                        subtask = Task(subattr, dst_id, subname)
                    unfinished_tasks[subpath] = subtask
                    submit(subtask)
                if not subattrs and remove_done:
                    try:
                        removedirs(src_path)
                    except OSError:
                        pass
                if pending_to_remove:
                    for i in range(0, len(pending_to_remove), 1_000):
                        part_ids = pending_to_remove[i:i+1_000]
                        try:
                            resp = fs.fs_delete(part_ids)
                            console_print(f"""\
[bold green][DELETE][/bold green] ðŸ“ åˆ é™¤æ–‡ä»¶åˆ—è¡¨
    â”œ ids({len(part_ids)}) = {part_ids}
    â”œ response = {resp}""")
                        except BaseException as e:
                            console_print(f"""[bold yellow][SKIP][/bold yellow] ðŸ“ åˆ é™¤æ–‡ä»¶åˆ—è¡¨å¤±è´¥
    â”œ ids({len(part_ids)}) = {part_ids}
    â”œ reason = [red]{type(e).__module__}.{type(e).__qualname__}[/red]: {e}""")
                update_success(1)
            else:
                kwargs: dict = {}
                if src_attr["size"] <= 1 << 30: # 1 GB
                    # NOTE: 1 GB ä»¥å†…ä½¿ç”¨ç½‘é¡µç‰ˆä¸Šä¼ æŽ¥å£ï¼Œè¿™ä¸ªæŽ¥å£çš„ä¼˜åŠ¿æ˜¯ä¸Šä¼ å®ŒæˆåŽä¼šè‡ªåŠ¨äº§ç”Ÿ 115 ç”Ÿæ´»äº‹ä»¶
                    kwargs["upload_directly"] = None
                elif src_attr["size"] > 1 << 34: # 16 GB
                    # NOTE: ä»‹äºŽ 1 GB å’Œ 16 GB æ—¶ç›´æŽ¥æµå¼ä¸Šä¼ ï¼Œè¶…è¿‡ 16 GB æ—¶ï¼Œä½¿ç”¨åˆ†å—ä¸Šä¼ ï¼Œåˆ†å—å¤§å° 1 GB
                    kwargs["partsize"] = 1 << 30

                filesize, filehash = hash_report(src_attr)
                console_print(f"[bold green][HASH][/bold green] ðŸ§  è®¡ç®—å“ˆå¸Œ: sha1([blue underline]{src_path!r}[/blue underline]) = {filehash.hexdigest()!r}")
                kwargs["filesize"] = filesize
                kwargs["filesha1"] = filehash.hexdigest()
                ticket: MultipartResumeData
                for i in range(5):
                    if i:
                        console_print(f"""\
[bold yellow][RETRY][/bold yellow] ðŸ“ é‡è¯•ä¸Šä¼ : [blue underline]{src_path!r}[/blue underline] âžœ [blue underline]{name!r}[/blue underline] in {dst_pid}
    â”œ ticket = {ticket}""")
                    try:
                        resp = client.upload_file(
                            src_path, 
                            name, 
                            pid=dst_pid, 
                            make_reporthook=partial(add_report, attr=src_attr), 
                            **kwargs, 
                        )
                        break
                    except MultipartUploadAbort as e:
                        exc = e
                        ticket = kwargs["multipart_resume_data"] = e.ticket
                else:
                    raise exc
                if resp.get("status") == 2 and resp.get("statuscode") == 0:
                    prompt = "ç§’ä¼ æ–‡ä»¶"
                else:
                    prompt = "ä¸Šä¼ æ–‡ä»¶"
                console_print(f"""\
[bold green][GOOD][/bold green] ðŸ“ {prompt}: [blue underline]{src_path!r}[/blue underline] âžœ [blue underline]{name!r}[/blue underline] in {dst_pid}
    â”œ response = {resp}""")
                update_success(1, 1, src_attr["size"])
                if remove_done:
                    try:
                        remove(src_path)
                    except OSError:
                        pass
                    try:
                        removedirs(dirname(src_path))
                    except OSError:
                        pass
            progress.update(statistics_bar, description=get_stat_str())
            success_tasks[src_path] = unfinished_tasks.pop(src_path)
        except BaseException as e:
            task.reasons.append(e)
            update_errors(e, src_attr["is_directory"])
            if max_retries < 0:
                status_code = get_status_code(e)
                if status_code:
                    retryable = status_code >= 500
                else:
                    retryable = isinstance(e, (RequestError, URLError, TimeoutError))
            else:
                retryable = task.times <= max_retries
            if retryable:
                console_print(f"""\
[bold red][FAIL][/bold red] â™»ï¸ å‘ç”Ÿé”™è¯¯ï¼ˆå°†é‡è¯•ï¼‰: [blue underline]{src_path!r}[/blue underline] âžœ [blue underline]{name!r}[/blue underline] in {dst_pid}
    â”œ [red]{type(e).__module__}.{type(e).__qualname__}[/red]: {e}""")
                update_retry(1, not src_attr["is_directory"])
                submit(task)
            else:
                console_print(f"""\
[bold red][FAIL][/bold red] ðŸ’€ å‘ç”Ÿé”™è¯¯ï¼ˆå°†æŠ›å¼ƒï¼‰: [blue underline]{src_path!r}[/blue underline] âžœ [blue underline]{name!r}[/blue underline] in {dst_pid}
{indent(format_exc().strip(), "    â”œ ")}""")
                progress.update(statistics_bar, description=get_stat_str())
                update_failed(1, not src_attr["is_directory"], src_attr.get("size"))
                failed_tasks[src_path] = unfinished_tasks.pop(src_path)
                if len(task.reasons) == 1:
                    raise
                else:
                    raise BaseExceptionGroup("max retries exceed", task.reasons)

    src_attr = get_path_attr(normpath(src_path))
    dst_attr = None
    name = src_attr["name"]
    is_directory = src_attr["is_directory"]
    with Progress(
        SpinnerColumn(), 
        *Progress.get_default_columns(), 
        TimeElapsedColumn(), 
        MofNCompleteColumn(), 
        DownloadColumn(), 
        FileSizeColumn(), 
        TransferSpeedColumn(), 
    ) as progress:
        console_print = lambda msg: progress.console.print(f"[bold][[cyan]{datetime.now()}[/cyan]][/bold]", msg)
        if isinstance(dst_path, str):
            if dst_path == "0" or not pnormpath(dst_path).strip("/"):
                dst_id = 0
            elif not dst_path.startswith("0") and dst_path.isascii() and dst_path.isdecimal():
                dst_id = int(dst_path)
            elif is_directory:
                dst_attr = fs.makedirs(dst_path, exist_ok=True)
                dst_path = dst_attr["path"]
                dst_id = dst_attr["id"]
            else:
                dst_dir, dst_name = split(dst_path)
                dst_attr = fs.makedirs(dst_dir, exist_ok=True)
                dst_path = dst_attr["path"] + "/" + escape(dst_name)
                dst_id = dst_attr["id"]
        else:
            dst_id = dst_path
        if name and is_directory and not no_root:
            dst_attr = fs.makedirs([name], pid=dst_id, exist_ok=True)
            dst_path = dst_attr["path"]
            dst_id = dst_attr["id"]
        if not dst_attr:
            dst_attr = fs.attr(dst_id)
            dst_path = cast(str, dst_attr["path"])
            if is_directory:
                if not dst_attr["is_directory"]:
                    raise NotADirectoryError(errno.ENOTDIR, dst_attr)
            elif dst_attr["is_directory"]:
                dst_path = dst_path + "/" + escape(name)
            else:
                fs.remove(dst_attr["id"])
                dst_id = dst_attr["parent_id"]
                name = dst_attr["name"]
        if is_directory:
            task = Task(src_attr, dst_id, dst_attr)
        else:
            task = Task(src_attr, dst_id, name)

        unfinished_tasks: dict[str, Task] = {src_attr["path"]: task}
        success_tasks: dict[str, Task] = {}
        failed_tasks: dict[str, Task] = {}
        all_tasks: Tasks = {
            "success": success_tasks, 
            "failed": failed_tasks, 
            "unfinished": unfinished_tasks, 
        }
        stats["src_path"] = src_attr["path"]
        stats["dst_path"] = dst_path
        update_tasks(1, not src_attr["is_directory"], src_attr.get("size"))
        get_stat_str = lambda: f"ðŸ“Š [cyan bold]statistics[/cyan bold] ðŸ§® {tasks['total']} = ðŸ’¯ {success['total']} + â›” {failed['total']} + â³ {unfinished['total']}"
        statistics_bar = progress.add_task(get_stat_str(), total=tasks["size"])
        closed = False
        try:
            thread_batch(work, unfinished_tasks.values(), max_workers=max_workers)
            stats["is_completed"] = True
        finally:
            closed = True
            progress.remove_task(statistics_bar)
            stats["elapsed"] = str(datetime.now() - start_time)
            console_print(f"ðŸ“Š [cyan bold]statistics:[/cyan bold] {stats}")
    return Result(stats, all_tasks)


parser.add_argument("-c", "--cookies", help="115 ç™»å½• cookiesï¼Œä¼˜å…ˆçº§é«˜äºŽ -cp/--cookies-path")
parser.add_argument("-cp", "--cookies-path", help="cookies æ–‡ä»¶ä¿å­˜è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰å·¥ä½œç›®å½•ä¸‹çš„ 115-cookies.txt")
parser.add_argument("-p", "--src-path", default=".", help="æœ¬åœ°çš„è·¯å¾„ï¼Œé»˜è®¤æ˜¯å½“å‰å·¥ä½œç›®å½•")
parser.add_argument("-t", "--dst-path", default="/", help="115 ç½‘ç›˜ä¸­çš„æ–‡ä»¶æˆ–ç›®å½•çš„ id æˆ–è·¯å¾„ï¼Œé»˜è®¤å€¼ï¼š'/'")
parser.add_argument("-m", "--max-workers", default=1, type=int, help="å¹¶å‘çº¿ç¨‹æ•°ï¼Œé»˜è®¤å€¼ 1")
parser.add_argument("-mr", "--max-retries", default=-1, type=int, 
                    help="""æœ€å¤§é‡è¯•æ¬¡æ•°ã€‚
    - å¦‚æžœå°äºŽ 0ï¼ˆé»˜è®¤ï¼‰ï¼Œåˆ™ä¼šå¯¹ä¸€äº›è¶…æ—¶ã€ç½‘ç»œè¯·æ±‚é”™è¯¯è¿›è¡Œæ— é™é‡è¯•ï¼Œå…¶å®ƒé”™è¯¯è¿›è¡ŒæŠ›å‡º
    - å¦‚æžœç­‰äºŽ 0ï¼Œåˆ™å‘ç”Ÿé”™è¯¯å°±æŠ›å‡º
    - å¦‚æžœå¤§äºŽ 0ï¼ˆå®žé™…æ‰§è¡Œ 1+n æ¬¡ï¼Œç¬¬ä¸€æ¬¡ä¸å«é‡è¯•ï¼‰ï¼Œåˆ™å¯¹æ‰€æœ‰é”™è¯¯ç­‰ç±»é½è§‚ï¼Œåªè¦æ¬¡æ•°åˆ°è¾¾æ­¤æ•°å€¼å°±æŠ›å‡º""")
parser.add_argument("-ur", "--use-request", choices=("httpx", "requests", "urllib3", "urlopen"), default="httpx", help="é€‰æ‹©ä¸€ä¸ªç½‘ç»œè¯·æ±‚æ¨¡å—ï¼Œé»˜è®¤å€¼ï¼šhttpx")
parser.add_argument("-n", "--no-root", action="store_true", help="ä¸Šä¼ ç›®å½•æ—¶ï¼Œç›´æŽ¥åˆå¹¶åˆ°ç›®æ ‡ç›®å½•ï¼Œè€Œä¸æ˜¯åˆ°ä¸Žæºç›®å½•åŒåçš„å­ç›®å½•")
parser.add_argument("-r", "--resume", action="store_true", help="æ–­ç‚¹ç»­ä¼ ")
parser.add_argument("-rm", "--remove-done", action="store_true", help="ä¸Šä¼ æˆåŠŸåŽï¼Œåˆ é™¤æœ¬åœ°æ–‡ä»¶")
parser.add_argument("-v", "--version", action="store_true", help="è¾“å‡ºç‰ˆæœ¬å·")
parser.set_defaults(func=main)


if __name__ == "__main__":
    main()

# TODO: statistics è¡Œè¦æœ‰æ›´è¯¦ç»†çš„ä¿¡æ¯ï¼Œå¦‚æžœä¸€è¡Œä¸å¤Ÿï¼Œå°±å†åŠ ä¸€è¡Œ
# TODO: ä»¥åŽè¦æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œå¯ç”¨ åˆ†å—ä¸Šä¼  å’Œ æœ¬åœ°ä¿å­˜è¿›åº¦
# TODO: ä»»åŠ¡å¯èƒ½è¦æ‰§è¡Œå¾ˆä¹…ï¼Œå…è®¸ä¸­é€”åˆ é™¤æ–‡ä»¶ï¼Œåˆ™è‡ªåŠ¨è·³è¿‡æ­¤ä»»åŠ¡
# TODO: è¿™ä¸ªæ¨¡å—åº”å¯ä»¥å•ç‹¬è¿è¡Œï¼Œä¹Ÿå¯ä»¥è¢« import
# TODO: æ”¯æŒåœ¨ä¸Šä¼ çš„æ—¶å€™ï¼Œæ”¹å˜æ–‡ä»¶çš„åå­—ï¼Œç‰¹åˆ«æ˜¯æ”¹å˜äº†æ‰©å±•åï¼Œåˆ™ç›´æŽ¥åˆ©ç”¨ç§’ä¼ å®žçŽ°
# TODO: å¦‚æžœæ–‡ä»¶å¤§äºŽç‰¹å®šå¤§å°ï¼Œå°±ä¸èƒ½ç§’ä¼ ï¼Œéœ€è¦ç›´æŽ¥æŠ¥é”™ï¼ˆè€Œä¸éœ€è¦è¿›è¡Œå°è¯•ï¼‰
# TODO: æ”¯æŒæŠŠä¸€ä¸ªç›®å½•ä¸Šä¼ åˆ°å¦ä¸€ä¸ªç›®å½•ï¼ˆå¦‚æžœæ‰©å±•åæ²¡æ”¹ï¼Œå°±ç›´æŽ¥å¤åˆ¶ï¼Œç„¶åŽæ”¹åï¼Œå¦åˆ™å°±ç§’ä¼ ï¼‰
# TODO: æ”¯æŒç›´æŽ¥ä»Žä¸€ä¸ª115ç½‘ç›˜ç›´æŽ¥ä¸Šä¼ åˆ°å¦ä¸€ä¸ª115ç½‘ç›˜
